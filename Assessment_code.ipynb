{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b606ec57-2672-40ac-9540-33347e7423df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DelimiterExample\").getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71f35084-5511-4577-85ba-82914630121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+---------+-------------------+--------------+-------+-----+-------+---------+--------+---------+\n",
      "|  H|Customer_Name|Customer_Id|Open_Date|Last_Consulted_Date|Vaccination_Id|Dr_Name|State|Country|Post_Code|     DOB|Is_Active|\n",
      "+---+-------------+-----------+---------+-------------------+--------------+-------+-----+-------+---------+--------+---------+\n",
      "|  D|        Jacob|     556270| 20011219|           20180614|           HPT|  Emily|  BOS|     UK|    59972|19700211|        N|\n",
      "|  D|       Mathew|     228782| 20040810|           20070418|           FLU|   John|  NYC|    GER|    39371|19930503|        A|\n",
      "|  D|       Mathew|     123982| 20171001|           20190908|           HPT|   Paul|  WAS|    CAN|    89702|19730131|        N|\n",
      "|  D|        Sarah|     398432| 20201212|           20170218|           HPT|   Mark|   AZ|     BR|    51761|19880413|        A|\n",
      "|  D|         John|     114905| 20061129|           20021020|           COV|  Emily|   FL|    GER|    22006|19860604|        A|\n",
      "+---+-------------+-----------+---------+-------------------+--------------+-------+-----+-------+---------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data with '|' as delimiter\n",
    "df = spark.read.option(\"delimiter\", \"|\").csv(\"/home/jovyan/work/data/customer_data.csv\",inferSchema=True, header=True)\n",
    "\n",
    "# Show the data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "934ce584-5c92-490f-832b-66602224bd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- H: string (nullable = true)\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Customer_Id: integer (nullable = true)\n",
      " |-- Open_Date: integer (nullable = true)\n",
      " |-- Last_Consulted_Date: integer (nullable = true)\n",
      " |-- Vaccination_Id: string (nullable = true)\n",
      " |-- Dr_Name: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Post_Code: integer (nullable = true)\n",
      " |-- DOB: integer (nullable = true)\n",
      " |-- Is_Active: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e37c226-7ca4-4a6e-bb9f-615575b4b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+----------+-------------------+--------------+-------+-----+-------+---------+----------+---------+\n",
      "|  H|Customer_Name|Customer_Id| Open_Date|Last_Consulted_Date|Vaccination_Id|Dr_Name|State|Country|Post_Code|       DOB|Is_Active|\n",
      "+---+-------------+-----------+----------+-------------------+--------------+-------+-----+-------+---------+----------+---------+\n",
      "|  D|        Jacob|     556270|2001-12-19|         2018-06-14|           HPT|  Emily|  BOS|     UK|    59972|1970-02-11|        N|\n",
      "|  D|       Mathew|     228782|2004-08-10|         2007-04-18|           FLU|   John|  NYC|    GER|    39371|1993-05-03|        A|\n",
      "|  D|       Mathew|     123982|2017-10-01|         2019-09-08|           HPT|   Paul|  WAS|    CAN|    89702|1973-01-31|        N|\n",
      "|  D|        Sarah|     398432|2020-12-12|         2017-02-18|           HPT|   Mark|   AZ|     BR|    51761|1988-04-13|        A|\n",
      "|  D|         John|     114905|2006-11-29|         2002-10-20|           COV|  Emily|   FL|    GER|    22006|1986-06-04|        A|\n",
      "+---+-------------+-----------+----------+-------------------+--------------+-------+-----+-------+---------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert the Open_Date, Last_Consulted_Date,DOB column in dateformat\n",
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Assuming df has a column 'date_col' with values like 20011219\n",
    "df1 = df.withColumn(\"Open_Date\", to_date(col(\"Open_Date\").cast(\"string\"), \"yyyyMMdd\"))\\\n",
    "        .withColumn(\"Last_Consulted_Date\",to_date(col(\"Last_Consulted_Date\").cast(\"string\"), \"yyyyMMdd\"))\\\n",
    "        .withColumn(\"DOB\",to_date(col(\"DOB\").cast(\"string\"), \"yyyyMMdd\"))\n",
    "\n",
    "# Show the result\n",
    "df1.select(\"*\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "712589d9-7b71-4348-a2b5-f5a1feecff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col, datediff, current_date, floor\n",
    "\n",
    "\n",
    "# Now calculate the age\n",
    "df2 = df1.withColumn(\"age\", floor(datediff(col(\"Last_Consulted_Date\"), col(\"DOB\")) / 365.25))\n",
    "df2=df2.withColumn('Customer_Id',col('Customer_Id').cast('String'))\n",
    "\n",
    "# Show the result\n",
    "df3=df2.select(\"Customer_Name\",\"Customer_Id\",\"Open_Date\",\"Last_Consulted_Date\",\"Vaccination_Id\",\"Dr_Name\",\"State\",\"Country\",\"Post_Code\",\"DOB\",\"Is_Active\",\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c758ad4-8d01-453b-b241-92d5521a5ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer_Name: string (nullable = true)\n",
      " |-- Customer_Id: string (nullable = true)\n",
      " |-- Open_Date: date (nullable = true)\n",
      " |-- Last_Consulted_Date: date (nullable = true)\n",
      " |-- Vaccination_Id: string (nullable = true)\n",
      " |-- Dr_Name: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Post_Code: integer (nullable = true)\n",
      " |-- DOB: date (nullable = true)\n",
      " |-- Is_Active: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1cc769-c55b-495e-a55c-be148425646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JDBC connection properties\n",
    "jdbc_url = \"jdbc:mysql://<hostname>:<port>/<database>\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"<db_user>\",\n",
    "    \"password\": \"<db_password>\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# SQL template to create tables\n",
    "create_table_sql_template = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS customer_data_{country} (\n",
    "    Customer_Name VARCHAR(255) NOT NULL,\n",
    "    Customer_Id VARCHAR(18) NOT NULL PRIMARY KEY,\n",
    "    Open_Date DATE NOT NULL,\n",
    "    Last_Consulted_Date DATE,\n",
    "    Vaccination_Type CHAR(5),\n",
    "    Doctor_Consulted VARCHAR(255),\n",
    "    State CHAR(5),\n",
    "    Country CHAR(5),\n",
    "    Post_Code INT,\n",
    "    DOB DATE,\n",
    "    Is_Active CHAR(1),\n",
    "    \n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Get the unique countries\n",
    "countries = df.select(\"Country\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Loop through each country and create table\n",
    "for country in countries:\n",
    "    create_table_sql = create_table_sql_template.format(country=country.lower())\n",
    "    \n",
    "    # Use PySpark's JDBC connection to execute the create table SQL query\n",
    "    spark.sql(create_table_sql)\n",
    "    print(f\"Created table for country: {country}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec0248-6f8d-4c52-99e3-9e7d025e8311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ebc0b-ea6f-4f1c-844e-65e1cdceacb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f401ad72-421b-4092-a1da-692d0bf7c72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be49a8e-f2c7-4d93-8d76-81a39176e7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fe1bc-4bca-45b1-b0b0-c99aa3c36533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ccff5-abda-4be5-b12c-f8a672054bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
